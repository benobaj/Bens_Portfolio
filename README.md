<img src="Resume.png" width="250" alt="My Image">


# Hello, I'm Benjamin Obaje
<a href="[https://linkedin.com](https://www.linkedin.com/in/ben-obaje-791b50186/)"><img src="https://img.shields.io/badge/-LinkedIn-0072b1?&style=for-the-badge&logo=linkedin&logoColor=white" /></a>


I am a recent graduate with a profound interest in technology and a dedication to solving complex problems. Accomplished Cybersecurity and Risk Analyst with proven success in enhancing operational efficiency and decision-making you will find a collection of projects and analyses that showcase my expertise and proficiency in handling and deriving insights from data. Whether it's unraveling trends, making informed business decisions, or uncovering valuable insights, this portfolio reflects my dedication to harnessing the power of data to drive strategic outcomes.

## Objective

My journey in computer science has led me to develop a passion for cybersecurity, and I am now eager to transition into this field, specifically aiming to be proffecient in operations and cybersecurity analysis.

## Skills

| Skill                                         | Associated Project         |
|-----------------------------------------------|----------------------------|
| •	Data Analysis & Visualization               | <a href="https://google.com">Detection Lab</a>|
| •	Compliance Monitoring                       | <a href="https://google.com">Detection Lab</a>|
| •	Incident response and remediation           | SOC Automation Lab|
| •	Risk assessment and mitigation              | SOC Automation Lab|
| •	Data Architecture                           | SOC Automation Lab|

## Tools
### Data Analytics Tools
<div>
    <img src="https://img.shields.io/badge/-MySql-1679A7?&style=for-the-badge&logo=Wireshark&logoColor=white" />
    <img src="https://img.shields.io/badge/-ExcelVBA-EF3B2D?&style=for-the-badge&logo=Suricata&logoColor=white" />
    <img src="https://img.shields.io/badge/-Python-777BB4?&style=for-the-badge&logo=Zeek&logoColor=white" />
</div>

### Business Intelligence tools
<div>
    <img src="https://img.shields.io/badge/-Tableau-00A4EF?&style=for-the-badge&logo=Microsoft&logoColor=white" />
    <img src="https://img.shields.io/badge/Microsoft%20Power%20BI-EF3B2D?style=for-the-badge&logo=powerbi&logoColor=white" />
    <img src="https://img.shields.io/badge/-Looker-4B275F?&style=for-the-badge&logo=Velociraptor&logoColor=white" />
</div>
### Business Intelligence tools
<div>
    <img src="https://img.shields.io/badge/-Tableau-00A4EF?&style=for-the-badge&logo=Microsoft&logoColor=white" />
    <img src="https://img.shields.io/badge/Microsoft%20Power%20BI-EF3B2D?style=for-the-badge&logo=powerbi&logoColor=white" />
    <img src="https://img.shields.io/badge/-Looker-4B275F?&style=for-the-badge&logo=Velociraptor&logoColor=white" />
</div>
### Cybersecurity tools
<div>
    <img src="https://img.shields.io/badge/-Splunk-4B3263?style=for-the-badge&logo=Splunk&logoColor=white" />
    <img src="https://img.shields.io/badge/-Wireshark-1679A7?style=for-the-badge&logo=Wireshark&logoColor=white" />
    <img src="https://img.shields.io/badge/-Snort-EF3B2D?style=for-the-badge&logo=Snort&logoColor=white" />
</p>


</div>


Portfolio Highlights:

Data Visualization: Explore my visualizations that transform complex data into comprehensible insights. From interactive dashboards to clear infographics, I emphasize the importance of communicating data effectively.

Data Quality Enhancement: Led data quality improvement initiatives, identifying and resolving data inconsistencies, duplicates, and missing values.
Implemented data validation checks and data cleansing procedures, resulting in data accuracy rates exceeding 98%.

Database Design and Optimization: Designed and optimized complex databases to efficiently store, manage, and retrieve large volumes of data.
Utilized indexing, query optimization, and performance tuning techniques, resulting in significant speed improvements.

Data Integration and ETL: Successfully integrated data from diverse sources, creating automated ETL (Extract, Transform, Load) processes.
Ensured seamless data flow between systems, enhancing cross-functional collaboration and data consistency.

Data Cleansing and Transformation: Learn about my meticulous approach to data preprocessing, ensuring that the insights drawn are accurate and reliable.

# FraudDetection

 This project showcases my work with machine learning and deep learning techniques to identify fraudulent activities. These projects have been part of my journey to deepen my understanding of data science, and I'm excited to share them with you.

## Projects
### [CreditCardFraud_Detection](https://github.com/benobaj/Fraud-Analysis)
This project explores credit card fraud detection using machine learning. It comprises three key parts:

1. **Logistic Regression**: I built a logistic regression model from scratch to classify credit card transactions as fraudulent or non-fraudulent. This involved data preprocessing, feature engineering, and model evaluation.

2. **Simple Neural Network**: Taking the basic logistic regression, I extended it to a simple deep feed-forward network using TensorFlow's low-level API. This step was a great introduction to neural networks and deep learning concepts.

3. **Keras Integration**: I integrated Keras to streamline building and training deep learning models. This helped improve my workflow and allowed me to experiment with more complex architectures.

Throughout this project, I learned to work with imbalanced datasets and applied techniques like oversampling to address class imbalance.

### Anomaly_Detection_with_RNN
In this project, I focused on detecting anomalies in user activities using a Long Short-Term Memory (LSTM) network with PyTorch. This unsupervised learning approach was a challenging yet rewarding experience. The goal was to create a model that could identify unusual patterns without relying on labeled data.

The insights gained from this project can be applied to a variety of scenarios, such as detecting data theft or monitoring online shopping for fraudulent activities.


This README presents the projects from a personal perspective, highlighting the skills and experiences gained while working on them. It outlines the different components and provides instructions for interacting with the repository, inviting contributions and questions. Ensure you update placeholders with your GitHub username and contact information before using this in your project.




# [Project Energy Consumption ](Energyconsumption/HourlyEnergyConsumptionpage.md)
Description:
The Python code is designed to analyze and visualize global energy consumption data. It aims to provide insights into the trends and patterns of energy consumption across different regions and energy sources. The code utilizes various libraries and techniques to process and visualize the data effectively.

Key Features:

Data Retrieval and Preparation: The code begins by retrieving energy consumption data from a reliable sources, international energy agencies and databases. The data is then cleaned and organized for further analysis.

Data Analysis:

Region-wise Analysis: The code categorizes countries into regions (e.g., continents) and calculates the total energy consumption for each region over a specific time period.
Energy Source Analysis: It analyzes the energy consumption distribution across different sources like fossil fuels (coal, oil, natural gas), renewable sources (solar, wind, hydro), and nuclear energy.
Trends and Patterns: The code identifies trends and patterns in energy consumption, such as growth rates, changes in consumption over time, and shifts in energy source preferences.

# [Project 1: Maximo LookerStudio](https://lookerstudio.google.com/reporting/e1fbfc58-a0dc-48d3-8b5f-8cf12e61aa23)

This dashboard provides a real-time visual picture of the manufacturing process in Maximo. Manufacturing dashboards display information and insights on each department's financial situation throughout the course of the year. Obtaining production-related metrics data from the previous shift or day, such as sales and performance relative to goals, are examples of the type of data. The data is now 12 to 24 hours old.  After that, I compile this data into status reports for the directors. The focus is typically on direct expenses and performance relative to the plan. 


##  Looker Company Overview Dashboard
![](Lookerstudiodashboard/Pic%201.png) 
##  Looker Company Financial Report
![](Lookerstudiodashboard/Pic%202.png) 
##  Looker Studio Designers/Manufacturing Report
![](Lookerstudiodashboard/Pic%203.png) 

# [Project 2: TankJuice Storemanagement](https://docs.google.com/spreadsheets/d/1nEaTTt8odZ6MsGqOxkRwnXm_1DUOrBp_SKFCkDBndjw/edit?usp=sharing)

The administration of the Tankjuice Store oversees and manages all business activities. Working with staff, making work plans, corresponding with suppliers, and handling consumer complaints are some of its primary tasks. Simple job delegation and priority setting for your team's top priorities. Organise your team's task, set project deadlines and milestones, and monitor progress all in one location. To construct an autonomous workflow system using holistics as a data warehouse and retain a LIVE dashboard and updates on their daily operations, they used Tableau, Excel, and Google.

* Data was taken from POS systems into the data warehouse 
* The model uses both; content-based filtering techniques and collaborative filtering techniques. 
* Coding Used : VBA, SQL and Google appscript and javascript

## Overview Of TankkJuice SMT DashBoard 
![](TankJuiceImage/Pic%201.png) 
## Running Sales and COG Forecaste 
![](TankJuiceImage/Pic%202.png) 


# [Project 3: MAXIMO Manufacturing and Operation Data architecture](https://docs.google.com/spreadsheets/d/1iTGZgBQPVSjoE60fn6V6jQt_tMf1DCQ3/edit?usp=sharing&ouid=115884990578000692853&rtpof=true&sd=true)

Maximo Manufacturing dashboards save the time it takes to respond to operational issues, and by giving management a better understanding of minute-by-minute operations, they provide crucial information so they can plan a reaction. Common KPIs include: Delivery performance
Manufacturing lead time, often known as "total cycle time," is the amount of time it takes for an order to go through the production.
OEE is valuable since it compiles information on output rates, product quality, and machine availability. The business intelligence system powers these dashboards. In order to give KPIs like order intake, warranty costs, delivery schedule achievement, and (of course) cash flow, this collects data from ERP, MES, and other systems.

##  Maximo Data Workflow
![](MAXIMO%20DAN%20DASHBOARD/Pic%203.png) 
##  Maximo Dashboard 
![](MAXIMO%20DAN%20DASHBOARD/Pic%201.png) 
##  Maximo Report Sheet 
![](MAXIMO%20DAN%20DASHBOARD/Pic%202.png) 



